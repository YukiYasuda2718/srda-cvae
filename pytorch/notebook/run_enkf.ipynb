{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b9fbe-4c25-45f5-a029-1ccb9e9df387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507f9d0-2d60-4338-93ea-33e8b1e7942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a3ce2-56ef-4c46-991e-41b912af9fbb",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d826fe4-63c8-42bb-8066-0896445693ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from cfd_model.cfd.periodic_channel_domain import TorchSpectralModel2D\n",
    "from cfd_model.enkf.sr_enkf import (\n",
    "    assimilate_with_existing_data,\n",
    "    calc_localization_matrix,\n",
    ")\n",
    "from cfd_model.filter.low_pass_periodic_channel_domain import LowPassFilter\n",
    "from cfd_model.initialization.periodic_channel_jet_initializer import calc_jet_forcing\n",
    "from cfd_model.interpolator.torch_interpolator import interpolate_time_series\n",
    "from src.dataloader import split_file_paths\n",
    "from src.utils import set_seeds, write_pickle\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94abe74-687b-4a95-9407-ca41412c2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)\n",
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c290751-03b3-4e4b-b99b-475f37ad1f1b",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce4b26-ff78-42b0-942a-748481aec5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa1dd3-dabd-4188-a34e-d9d371ae80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRDA_CONFIG_NAME = \"default_neural_nets\"\n",
    "\n",
    "with open(f\"{ROOT_DIR}/pytorch/config/{SRDA_CONFIG_NAME}.yml\") as file:\n",
    "    CONFIG = yaml.safe_load(file)\n",
    "\n",
    "SRDA_DATA_DIR = f\"{ROOT_DIR}/data/SRDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c201215-08db-402d-9353-040f8731fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_GRID_INTERVAL = 8\n",
    "\n",
    "ENKF_PREFERENCES = {\n",
    "    8: {\n",
    "        \"INIT_SYS_NOISE_FACTOR\": 0.4,\n",
    "        \"LOCALIZE_DX\": 0.5,\n",
    "        \"N_ENS\": 300.0,\n",
    "        \"OBS_PERTURB_STD\": 0.65,\n",
    "        \"SYS_NOISE_FACTOR\": 0.2,\n",
    "    },\n",
    "}\n",
    "\n",
    "ENKF_DATA_DIR = f\"{ROOT_DIR}/data/EnKF\"\n",
    "os.makedirs(ENKF_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe9785-9b91-40af-9c78-fd282cbc2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VALID_TEST_RATIOS = [0.7, 0.2, 0.1]\n",
    "\n",
    "INITIAL_TIME_INDEX = 16\n",
    "SEED = 42\n",
    "INFLATION = 1.0\n",
    "\n",
    "ASSIMILATION_PERIOD = 4\n",
    "OBS_NOISE_STD = 0.1\n",
    "\n",
    "LR_NX = 32\n",
    "LR_NY = 17\n",
    "LR_DT = 5e-4\n",
    "LR_NT = 500\n",
    "\n",
    "HR_NX = 128\n",
    "HR_NY = 65\n",
    "\n",
    "Y0 = np.pi / 2.0\n",
    "SIGMA = 0.4\n",
    "U0 = 3.0\n",
    "TAU0 = 0.3\n",
    "PERTUB_NOISE = 0.0025\n",
    "\n",
    "BETA = 0.1\n",
    "COEFF_LINEAR_DRAG = 1e-2\n",
    "ORDER_DIFFUSION = 2\n",
    "LR_COEFF_DIFFUSION = 5e-5\n",
    "\n",
    "DT = LR_DT * LR_NT\n",
    "\n",
    "LR_CFD_CONFIG = {\n",
    "    \"nx\": LR_NX,\n",
    "    \"ny\": LR_NY,\n",
    "    \"lr_nx\": LR_NX,\n",
    "    \"lr_ny\": LR_NY,\n",
    "    \"hr_nx\": HR_NX,\n",
    "    \"hr_ny\": HR_NY,\n",
    "    \"assimilation_period\": ASSIMILATION_PERIOD,\n",
    "    \"coeff_linear_drag\": COEFF_LINEAR_DRAG,\n",
    "    \"coeff_diffusion\": LR_COEFF_DIFFUSION,\n",
    "    \"order_diffusion\": ORDER_DIFFUSION,\n",
    "    \"beta\": BETA,\n",
    "    \"device\": DEVICE,\n",
    "    \"y0\": Y0,\n",
    "    \"sigma\": SIGMA,\n",
    "    \"tau0\": TAU0,\n",
    "    \"t0\": INITIAL_TIME_INDEX * LR_DT * LR_NT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf7ded-57c1-429d-bc55-36208ad25cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ENS = int(ENKF_PREFERENCES[OBS_GRID_INTERVAL][\"N_ENS\"])\n",
    "LOCALIZE_DX = ENKF_PREFERENCES[OBS_GRID_INTERVAL][\"LOCALIZE_DX\"]\n",
    "SYS_NOISE_FACTOR = ENKF_PREFERENCES[OBS_GRID_INTERVAL][\"SYS_NOISE_FACTOR\"]\n",
    "INIT_SYS_NOISE_FACTOR = ENKF_PREFERENCES[OBS_GRID_INTERVAL][\"INIT_SYS_NOISE_FACTOR\"]\n",
    "OBS_PERTURB_STD = ENKF_PREFERENCES[OBS_GRID_INTERVAL][\"OBS_PERTURB_STD\"]\n",
    "\n",
    "LOCALIZE_DY = LOCALIZE_DX\n",
    "LR_CFD_CONFIG[\"ne\"] = int(N_ENS)\n",
    "LR_CFD_CONFIG[\"n_ens\"] = int(N_ENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3271f5-32ad-415d-9131-9ef9e654ea78",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586ea3d-d792-484c-85cf-ce132e159b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pass_filter = LowPassFilter(\n",
    "    nx_lr=LR_NX, ny_lr=LR_NY, nx_hr=HR_NX, ny_hr=HR_NY, device=DEVICE\n",
    ")\n",
    "\n",
    "\n",
    "def initialize_lr_model(\n",
    "    *,\n",
    "    t0: float,\n",
    "    hr_omega0: torch.Tensor,\n",
    "    lr_forcing: torch.Tensor,\n",
    "    lr_model: TorchSpectralModel2D,\n",
    "    n_ens: int,\n",
    "    hr_nx: int,\n",
    "    hr_ny: int,\n",
    "    lr_nx: int,\n",
    "    lr_ny: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    assert hr_omega0.shape == (hr_nx, hr_ny)\n",
    "    omega0 = low_pass_filter.apply(hr_omega0[None, ...])\n",
    "    omega0 = torch.broadcast_to(omega0, (n_ens, lr_nx, lr_ny))\n",
    "\n",
    "    lr_model.initialize(t0=t0, omega0=omega0, forcing=lr_forcing)\n",
    "    lr_model.calc_grid_data()\n",
    "\n",
    "\n",
    "def load_hr_data(\n",
    "    root_dir: str,\n",
    "    train_valid_test_ratios: typing.List[str],\n",
    "    kind: str,\n",
    "    num_hr_omega_sets: int,\n",
    "    max_ens_index: int = 20,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    training_data_dir_path = f\"{root_dir}/data/TrainingData\"\n",
    "    logger.info(f\"Training data dir path = {training_data_dir_path}\")\n",
    "\n",
    "    data_dirs = sorted(\n",
    "        [p for p in glob.glob(f\"{training_data_dir_path}/*\") if os.path.isdir(p)]\n",
    "    )\n",
    "\n",
    "    train_dirs, valid_dirs, test_dirs = split_file_paths(\n",
    "        data_dirs, train_valid_test_ratios\n",
    "    )\n",
    "\n",
    "    if kind == \"train\":\n",
    "        target_dirs = train_dirs\n",
    "    elif kind == \"valid\":\n",
    "        target_dirs = valid_dirs\n",
    "    elif kind == \"test\":\n",
    "        target_dirs = test_dirs\n",
    "    else:\n",
    "        raise Exception(f\"{kind} is not supported.\")\n",
    "\n",
    "    logger.info(f\"Kind = {kind}, Num of dirs = {len(target_dirs)}\")\n",
    "\n",
    "    all_hr_omegas = []\n",
    "    for dir_path in sorted(target_dirs):\n",
    "        for i in range(max_ens_index):\n",
    "\n",
    "            hr_omegas = []\n",
    "            for file_path in sorted(glob.glob(f\"{dir_path}/*_hr_omega_{i:02}.npy\")):\n",
    "                data = np.load(file_path)\n",
    "\n",
    "                # This is to avoid overlapping at the start/end point\n",
    "                if len(hr_omegas) > 0:\n",
    "                    data = data[1:]\n",
    "                hr_omegas.append(data)\n",
    "\n",
    "            # Concat along time axis\n",
    "            all_hr_omegas.append(np.concatenate(hr_omegas, axis=0))\n",
    "\n",
    "            if len(all_hr_omegas) == num_hr_omega_sets:\n",
    "                # Concat along batch axis\n",
    "                ret = np.stack(all_hr_omegas, axis=0)\n",
    "                return torch.from_numpy(ret).to(torch.float64)\n",
    "\n",
    "    ret = np.stack(all_hr_omegas, axis=0)\n",
    "    return torch.from_numpy(ret).to(torch.float64)\n",
    "\n",
    "\n",
    "def get_sys_noise_generator(num_hr_omega_sets: int = 250, eps: float = 1e-12):\n",
    "    hr_omegas = load_hr_data(\n",
    "        root_dir=ROOT_DIR,\n",
    "        train_valid_test_ratios=TRAIN_VALID_TEST_RATIOS,\n",
    "        kind=\"train\",\n",
    "        num_hr_omega_sets=num_hr_omega_sets,\n",
    "    )\n",
    "    hr_omegas = hr_omegas[:, INITIAL_TIME_INDEX:]\n",
    "\n",
    "    # dims = batch, time, x, and y\n",
    "\n",
    "    lr_omegas = interpolate_time_series(hr_omegas, LR_NX, LR_NY, \"bicubic\")\n",
    "    lr_omegas = lr_omegas - torch.mean(lr_omegas, dim=0, keepdim=True)\n",
    "\n",
    "    lr_omegas = lr_omegas.reshape(lr_omegas.shape[:2] + (-1,))\n",
    "    # dims = batch, time, and space\n",
    "\n",
    "    del hr_omegas\n",
    "    gc.collect()\n",
    "\n",
    "    # Inner product over batch dim\n",
    "    all_covs = torch.mean(lr_omegas[..., None, :] * lr_omegas[..., None], dim=0)\n",
    "\n",
    "    # Assure conv is symmetric.\n",
    "    all_covs = (all_covs + all_covs.permute(0, 2, 1)) / 2.0\n",
    "\n",
    "    # Assure positive definiteness\n",
    "    all_covs = all_covs + torch.diag(\n",
    "        torch.full(size=(all_covs.shape[-1],), fill_value=eps)\n",
    "    )\n",
    "\n",
    "    loc = torch.zeros(all_covs.shape[-1], dtype=torch.float64)\n",
    "    return [MultivariateNormal(loc, cov) for cov in all_covs]\n",
    "\n",
    "\n",
    "def get_obs_matrix(obs: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    assert obs.shape == (HR_NX, HR_NY)\n",
    "    is_obs = torch.where(torch.isnan(obs), torch.zeros_like(obs), torch.ones_like(obs))\n",
    "\n",
    "    _is_obs = is_obs.reshape(-1)\n",
    "    obs_indices = torch.where(_is_obs == 1.0)[0]\n",
    "\n",
    "    num_obs = len(obs_indices)\n",
    "\n",
    "    obs_matrix = torch.zeros(num_obs, HR_NX * HR_NY, dtype=torch.float64, device=DEVICE)\n",
    "\n",
    "    for i, j in enumerate(obs_indices):\n",
    "        obs_matrix[i, j] = 1.0\n",
    "\n",
    "    p = 100 * torch.sum(obs_matrix).item() / (HR_NX * HR_NY)\n",
    "    logger.debug(f\"observatio prob = {p} [%]\")\n",
    "\n",
    "    return obs_matrix\n",
    "\n",
    "\n",
    "def get_all_srda_result_paths(config_name: str = SRDA_CONFIG_NAME):\n",
    "    sr_prior_file_path = f\"{SRDA_DATA_DIR}/sr_prior_{config_name}.npy\"\n",
    "    sr_analysis_file_path = f\"{SRDA_DATA_DIR}/sr_analysis_{config_name}.npy\"\n",
    "    lr_omega_file_path = f\"{SRDA_DATA_DIR}/lr_omega_{config_name}.npy\"\n",
    "    hr_omega_file_path = f\"{SRDA_DATA_DIR}/hr_omega_{config_name}.npy\"\n",
    "    hr_obsrv_file_path = f\"{SRDA_DATA_DIR}/hr_obsrv_{config_name}.npy\"\n",
    "\n",
    "    return (\n",
    "        sr_prior_file_path,\n",
    "        sr_analysis_file_path,\n",
    "        lr_omega_file_path,\n",
    "        hr_omega_file_path,\n",
    "        hr_obsrv_file_path,\n",
    "    )\n",
    "\n",
    "\n",
    "def read_all_srda_result_files(config_name: str = SRDA_CONFIG_NAME):\n",
    "    (\n",
    "        sr_prior_file_path,\n",
    "        sr_analysis_file_path,\n",
    "        lr_omega_file_path,\n",
    "        hr_omega_file_path,\n",
    "        hr_obsrv_file_path,\n",
    "    ) = get_all_srda_result_paths(config_name)\n",
    "\n",
    "    return (\n",
    "        np.load(sr_prior_file_path),\n",
    "        np.load(sr_analysis_file_path),\n",
    "        np.load(lr_omega_file_path),\n",
    "        np.load(hr_omega_file_path),\n",
    "        np.load(hr_obsrv_file_path),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adf23f-0063-4dd4-8fbb-4b7cdc33224b",
   "metadata": {},
   "source": [
    "# Read ground truth and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7ba54-9027-449a-9393-9a7f92ea09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, _, _, all_hr_omegas, all_hr_obsrv) = read_all_srda_result_files(SRDA_CONFIG_NAME)\n",
    "all_hr_omegas = torch.from_numpy(all_hr_omegas)\n",
    "all_hr_obsrv = torch.from_numpy(all_hr_obsrv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a6834-1183-4f2a-a734-b3aef23831a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all_hr_omegas.shape == all_hr_obsrv.shape == (500, 81, 128, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986de9ee-e52d-4b43-a69a-d4ccb55b0e84",
   "metadata": {},
   "source": [
    "# Perform enkf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad4df5-42a3-4380-98d5-aba1fa9b4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(SEED, use_deterministic=True)\n",
    "\n",
    "sys_noise_generators = get_sys_noise_generator()\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba5998-06ec-4109-abaf-e4fb7ff03ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sys_noise_generators) == all_hr_omegas.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a31139-1936-4199-ad52-1a01a880d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_rand_generator = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "localization_matrix = calc_localization_matrix(\n",
    "    nx=HR_NX, ny=HR_NY, d_x=LOCALIZE_DX, d_y=LOCALIZE_DY\n",
    ").to(DEVICE)\n",
    "\n",
    "max_time_index = all_hr_omegas.shape[1]\n",
    "assert max_time_index == 81\n",
    "\n",
    "# Initialize with the hr simulation results at the initial time without noise\n",
    "init_hr_omegas = all_hr_omegas[:, 0]\n",
    "assert init_hr_omegas.shape == (500, HR_NX, HR_NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a821b0b-9b8b-4341-865e-413e2cbff43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hr_obsrv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714320e7-e3b9-4c78-b116-dc15ddead969",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_ens in tqdm(range(all_hr_omegas.shape[0])):\n",
    "    output_lr_file_path = (\n",
    "        f\"{ENKF_DATA_DIR}/ens_all_lr_forecast_og{OBS_GRID_INTERVAL:02}_{i_ens:04}.npy\"\n",
    "    )\n",
    "    output_hr_file_path = (\n",
    "        f\"{ENKF_DATA_DIR}/ens_mean_hr_og{OBS_GRID_INTERVAL:02}_{i_ens:04}.pickle\"\n",
    "    )\n",
    "    if os.path.exists(output_lr_file_path) or os.path.exists(output_hr_file_path):\n",
    "        continue\n",
    "\n",
    "    logger.setLevel(WARNING)\n",
    "    lr_model = TorchSpectralModel2D(**LR_CFD_CONFIG)\n",
    "    _, lr_forcing = calc_jet_forcing(**LR_CFD_CONFIG)\n",
    "    logger.setLevel(INFO)\n",
    "\n",
    "    initialize_lr_model(\n",
    "        hr_omega0=init_hr_omegas[i_ens].clone(),  # dims = x and y only\n",
    "        lr_forcing=lr_forcing,\n",
    "        lr_model=lr_model,\n",
    "        **LR_CFD_CONFIG,\n",
    "    )\n",
    "\n",
    "    lr_enkfs = []\n",
    "    dict_hr_analysis = {}\n",
    "\n",
    "    for i_cycle in tqdm(range(max_time_index)):\n",
    "\n",
    "        lr_enkfs.append(lr_model.omega.cpu().clone())\n",
    "\n",
    "        # Data assimilation\n",
    "        if i_cycle > 0 and i_cycle % ASSIMILATION_PERIOD == 0:\n",
    "            obs = all_hr_obsrv[i_ens, i_cycle].to(torch.float64)\n",
    "            obs_matrix = get_obs_matrix(obs)\n",
    "\n",
    "            # This is to avoid nan when observation operator acts.\n",
    "            obs = torch.nan_to_num(obs, nan=1e10)\n",
    "\n",
    "            # This method returns forecast conv\n",
    "            all_hr_analysis = assimilate_with_existing_data(\n",
    "                hr_omega=obs.to(DEVICE),\n",
    "                lr_ens_model=lr_model,\n",
    "                obs_matrix=obs_matrix,\n",
    "                obs_noise_std=OBS_PERTURB_STD,\n",
    "                inflation=INFLATION,\n",
    "                rand_generator=torch_rand_generator,\n",
    "                localization_matrix=localization_matrix,\n",
    "                return_hr_analysis=True,\n",
    "            )\n",
    "\n",
    "            # Mean over batch (ensemble dim)\n",
    "            assert all_hr_analysis.shape == (N_ENS, HR_NX, HR_NY)\n",
    "            hr_analysis = torch.mean(all_hr_analysis, axis=0)\n",
    "            dict_hr_analysis[i_cycle] = hr_analysis.cpu().to(torch.float32).numpy()\n",
    "\n",
    "        # Add additive system noise\n",
    "        if i_cycle == 0 or (INFLATION == 1.0 and i_cycle % ASSIMILATION_PERIOD == 0):\n",
    "            noise = sys_noise_generators[i_cycle].sample([N_ENS])\n",
    "            noise = noise.reshape(N_ENS, LR_NX, LR_NY)\n",
    "            noise = noise - torch.mean(noise, dim=0, keepdims=True)\n",
    "\n",
    "            factor = INIT_SYS_NOISE_FACTOR if i_cycle == 0 else SYS_NOISE_FACTOR\n",
    "            omega = lr_model.omega + factor * noise.to(DEVICE)\n",
    "\n",
    "            lr_model.initialize(t0=lr_model.t, omega0=omega)\n",
    "            lr_model.calc_grid_data()\n",
    "\n",
    "        lr_model.time_integrate(dt=LR_DT, nt=LR_NT, hide_progress_bar=True)\n",
    "        lr_model.calc_grid_data()\n",
    "\n",
    "    write_pickle(dict_hr_analysis, output_hr_file_path)\n",
    "\n",
    "    # Stack along time dim\n",
    "    lr_enkfs = torch.stack(lr_enkfs, dim=1).to(torch.float32).numpy()\n",
    "    assert lr_enkfs.shape == (N_ENS, 81, LR_NX, LR_NY)\n",
    "    np.save(output_lr_file_path, lr_enkfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa21e08-cd49-4e49-a4b0-b8ca79f4bf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
